{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andreas Mueller, Kyle Kastner, Sebastian Raschka \n",
      "last updated: 2017-06-13 \n",
      "\n",
      "CPython 3.6.1\n",
      "IPython 6.0.0\n",
      "\n",
      "numpy 1.12.1\n",
      "scipy 0.18.1\n",
      "matplotlib 2.0.2\n",
      "sklearn 0.18.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark  -d -u -a 'Andreas Mueller, Kyle Kastner, Sebastian Raschka' -v -p numpy,scipy,matplotlib,sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.594090\n",
      "n_neighbors: 3, average score: 0.709107\n",
      "n_neighbors: 5, average score: 0.728316\n",
      "n_neighbors: 10, average score: 0.734162\n",
      "n_neighbors: 20, average score: 0.613750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "\n",
    "cv = KFold(shuffle=True, n_splits=5)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x10a33f908>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10eb2def0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_errors, test_errors = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_errors.mean(axis=1), label=\"train error\")\n",
    "plt.plot(n_neighbors, test_errors.mean(axis=1), label=\"test error\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot is the mirror image of the diagram above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.288339\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.084360\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.103188\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.067030\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.016993\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.022610\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.065478\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.042556\n",
      "C: 0.100000, gamma: 0.001000, average score: 0.017943\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.125724\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.536239\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.503732\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.202089\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.587744\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.671638\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.698322\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.588402\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.590441\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.644546\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.757024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.763289, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.136112, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.489024, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.450817, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.323774, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.498079, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.647897, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.702430, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.519666, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.418887, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.833522, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.292157, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.556659, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.493903, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.595434, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.846518, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.763448, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.853713, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.609304, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.741626, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.844254, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.383796, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.528571, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.527226, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.702951, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.885414, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.757999, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.849066, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.712505, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.780549, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.865954, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] .................. n_neighbors=10, score=-0.090287, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.576486, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.512557, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.789334, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.862289, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.672361, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.897859, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.827408, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.827001, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ................... n_neighbors=20, score=0.837873, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] .................. n_neighbors=20, score=-0.356936, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ................... n_neighbors=20, score=0.566725, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ................... n_neighbors=20, score=0.472988, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ................... n_neighbors=20, score=0.787047, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ................... n_neighbors=20, score=0.700890, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ................... n_neighbors=20, score=0.483719, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ................... n_neighbors=20, score=0.817299, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ................... n_neighbors=20, score=0.817023, total=   0.0s\n",
      "[CV] n_neighbors=20 ..................................................\n",
      "[CV] ................... n_neighbors=20, score=0.777065, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.652859, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.378736, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.534933, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.398544, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.659048, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.542210, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.196311, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.705631, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.761936, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.591326, total=   0.0s\n",
      "0.697233061688\n",
      "{'n_neighbors': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 10, 20, 50]}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsRegressor(), param_grid=param_grid, cv=cv, verbose=3)\n",
    "grid.fit(X, y)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.001503, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.028499, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.025868, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.078651, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.000385, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .............. C=0.001, gamma=0.01, score=0.001027, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.026697, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.023367, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.075782, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .............. C=0.001, gamma=0.01, score=0.002258, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.011697, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.018317, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.012409, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.061659, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.013903, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.009674, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.018636, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.014235, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.063234, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.012257, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .............. C=0.01, gamma=0.001, score=0.001299, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.026542, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.023112, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.075489, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .............. C=0.01, gamma=0.001, score=0.002528, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.026227, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.009579, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.001649, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.043225, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.028751, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.119398, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.073163, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.100676, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.074522, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.134586, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.103714, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.062414, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.075578, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.065425, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.119951, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.028545, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.007841, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.004563, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.040038, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.031393, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.228569, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.137944, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.189400, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.174564, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.227052, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.547432, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.446986, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.508949, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.578931, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.629419, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.489043, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.434560, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.475826, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.578489, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.605938, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.247950, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.140911, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.203450, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.194529, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.245333, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.606339, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.482652, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.560204, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.656194, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.720401, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.651697, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.541411, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.617207, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.764114, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.815967, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.622148, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.606998, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.672507, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.841479, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.858108, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.605189, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=10, gamma=0.001, score=0.484438, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.552653, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.642333, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.716854, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.602412, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.511320, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.559142, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.691499, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.765998, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.648418, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.530516, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.620599, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.775325, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.817838, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.482627, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.710253, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.722949, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.872276, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.860050, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.729631022028\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.054851, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.053257, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.046097, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.047294, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.053101, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.038283, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.020889, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.017537, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.037152, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.088481, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.434562, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.402364, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.089853, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.568843, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.737686, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.778568, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.577172, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.642011, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.760004, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.854564, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/14_grid_search.py\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
